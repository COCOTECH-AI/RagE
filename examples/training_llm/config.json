{
    "name": "fine_tune_llm_qa_abtract", 
    "tokenizer_name": "bigscience/bloomz-1b1", 
    "architectures": {
        "model_name": "bigscience/bloomz-1b1",
        "type_backbone": "casual_lm", 
        "lora_r": 16, 
        "lora_alpha": 32, 
        "lora_dropout": 0.05, 
        "target_modules": ["query_key_value", "lm_head"], 
        "merge_lora": false, 
        "gradient_ckpt": true, 
        "use_cache": false
    },
    "max_length": 1024,
    "batch_size": 16,
    "shuffle": true, 
    "num_workers": 16, 
    "pin_memory": true, 
    "prefetch_factor": 8, 
    "persistent_workers": true, 
    "gradient_accumlation_steps": 8, 
    "learning_rate": 5e-5, 
    "weight_decay": 0.1, 
    "eps": 1e-6, 
    "warmup_steps": 200, 
    "epochs": 3, 
    "path_ckpt_step": "step_qa.pt", 
    "verbose": 1, 
    "step_save": 100, 
    "path_ckpt_epoch": "best_qa.pt", 
    "path_train": "/home/supfleur/doan/examples/training_llm/synthetic_data.json",
    "path_eval": null, 
    "device": "cuda"
}