{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from rag_chatbot import GenAnsModelCasualLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForCausalLM were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model= GenAnsModelCasualLM('bigscience/bloom-560m', device= device, lora_r= 16, lora_alpha= 32, \n",
    "                           lora_dropout= 0.05, target_modules= [\"query_key_value\", \"lm_head\"], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prepare_inference(ckpt_dir= 'best_qa_vi_squad_v2_lmhead_1.pt', merge_lora= True, torch_compile= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx= \"\"\"Xin chào, tôi tên là UTT Assistant, một trí tuệ nhân tạo được phát triển nhằm giải đáp thông tin cho sinh viên ĐH CN GTVT. \n",
    "Tôi được tạo ra bằng công nghệ học máy sâu trên nền mô hình ngôn ngữ đã được huấn luyện hằng trăm triệu điểm dữ liệu trước đó rồi được tinh chỉnh để có thể trả lời câu hỏi như hiện tại. \n",
    "Phiên bản đầu tiên của tôi cũng chính là ngày tôi mới sinh ra là vào ngày 10/10/2023. \n",
    "Tôi không có cảm xúc hay giới tính gì nhưng khả năng của tôi là luôn hỗ trợ giải đáp mọi thắc mắc cho các bạn sinh viên. \n",
    "Tôi hy vọng rằng có thể giúp bạn với các câu hỏi yêu cầu của bạn\"\"\"\n",
    "\n",
    "config_gen= {'max_new_tokens': 100,\n",
    "            'top_k': 50, \n",
    "            'top_p': 0.9, \n",
    "            'temperature': 0.7,\n",
    "             'do_sample': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: Không biết'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gen([f'Context: {ctx}\\nQuestion: Bạn có giới tính ko\\nAnswer:'], config_gen= config_gen).split('\\n')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
